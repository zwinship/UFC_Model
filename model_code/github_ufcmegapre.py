# -*- coding: utf-8 -*-
"""github_UFCmegapre.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dcVQIAT9oGo8ZDsZk0wOMppuhaprjg2R
"""

# Standard library imports
import os
import sys
import re
import time
import pickle
import base64
from datetime import datetime

# Third-party imports
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import requests
from bs4 import BeautifulSoup
from lxml import html
import joblib

# Machine learning imports
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

# Selenium imports
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC



df = pd.read_csv("https://raw.githubusercontent.com/zwinship/UFC_Model/refs/heads/main/ufc-master.csv")
dfinst = pd.read_csv('https://raw.githubusercontent.com/Greco1899/scrape_ufc_stats/refs/heads/main/ufc_fight_stats.csv')
dfdet = pd.read_csv('https://raw.githubusercontent.com/zwinship/UFC_Model/refs/heads/main/data.csv')
dfj = pd.read_json('https://raw.githubusercontent.com/zwinship/UFC_Model/refs/heads/main/fighter_data.ndjson', lines = True)




pd.set_option('display.max_columns', None)
columns_list = list(df.columns)


# Creating lists for colunms that start with Red/Blue
red_cols = [col for col in df.columns if col.startswith('Red')]
blue_cols = [col.replace('Red', 'Blue') for col in red_cols]

#Removing Stance and Fighter from the list because this var is str
exclude_cols = ['Stance', 'Fighter']
red_cols = [col for col in red_cols if not any(ex in col for ex in exclude_cols)]
blue_cols = [col.replace('Red', 'Blue') for col in red_cols]

#Creating functions

# Natural log of input var
def logvar(df, var):
    df[var + 'Log'] = np.log(df[var])
    return df


# Binary var with inputs for when string = 1, and string = 0
def binary(df, column, one, zero):
    df[column + 'Binary'] = np.nan
    df.loc[df[column] == one, column + 'Binary'] = 1
    df.loc[df[column] == zero, column + 'Binary'] = 0
    return df

# Takes diff of two vars
def diffvars(df, red, blue):
    df['Diff' +  red.strip('Red')] = df[red] - df[blue]
    return df




# Making binary winner
df = binary(df, 'Winner', 'Red', 'Blue')


df['RedExpectedValue'] = np.log(df['RedExpectedValue'])
df['BlueExpectedValue'] = np.log(df['BlueExpectedValue'])


# Creating all of the diff columns
for red, blue in zip(red_cols, blue_cols):
    if red in df.columns:
        new_col = 'Diff' + red.replace('Red', '')
        df[new_col] = df[red] - df[blue]




# Create separate DataFrames for red and blue fighters with .copy() to avoid modifying the original DataFrame
df_red = dfdet.rename(columns={'R_fighter': 'fighter'}).drop(columns=['B_fighter'], errors='ignore').copy()
df_blue = dfdet.rename(columns={'B_fighter': 'fighter'}).drop(columns=['R_fighter'], errors='ignore').copy()

# Drop irrelevant columns for each
df_red = df_red[[col for col in df_red.columns if not col.startswith('B_avg_') and '_opp' not in col]]
df_blue = df_blue[[col for col in df_blue.columns if not col.startswith('R_avg_') and '_opp' not in col]]

# Rename columns to a common format (remove R_ and B_ prefixes)
df_red = df_red.rename(columns=lambda x: x.replace('R_avg_', 'avg_'))
df_blue = df_blue.rename(columns=lambda x: x.replace('B_avg_', 'avg_'))

# Drop duplicate fighters within each dataframe (keeping the first occurrence)
df_red = df_red.drop_duplicates(subset=['fighter'], keep='first')
df_blue = df_blue.drop_duplicates(subset=['fighter'], keep='first')

# Combine both DataFrames while keeping order intact
df_final = pd.concat([df_red, df_blue], ignore_index=True)

# Keep only 'fighter', 'weight_class', and columns that start with 'avg_'
df_final = df_final[[col for col in df_final.columns if col in ['fighter', 'weight_class'] or col.startswith('avg_')]]

# Drop rows where ALL 'avg_' columns are NaN (but keep fighter and weight_class)
avg_cols = [col for col in df_final.columns if col.startswith('avg_')]
dfdet = df_final.dropna(subset=avg_cols, how='all')

dfdet = dfdet.drop_duplicates(subset=['fighter'], keep='first')




################################################################################
################################################################################
################################################################################
# DFDET cleaning

# Standardize within each weight_class
dfdet = dfdet.copy()
dfdet[["std_" + col for col in avg_cols]] = dfdet.groupby("weight_class")[avg_cols].transform(lambda x: (x - x.mean()) / x.std())


dfdet.loc[:, 'std_avg_CTRL_time(seconds)'] = dfdet['std_avg_CTRL_time(seconds)'].fillna(-1)

dfdet



striker = -0.35
wrestler = 0
bjj = -0.45
thai = -0.43
sniper = -0.7

def get_fighting_style(row):
    if row['std_avg_KD'] >= striker and row['std_avg_SIG_STR_att'] >= striker and row['std_avg_TOTAL_STR_att'] >= striker and row['std_avg_HEAD_att'] >= striker:
        return 'Striker'

    elif row['std_avg_CTRL_time(seconds)'] >= wrestler and row['std_avg_GROUND_att'] >= wrestler and row['std_avg_TD_att'] >= wrestler:
        return 'Wrestler'

    elif row['std_avg_SUB_ATT'] >= bjj and row['std_avg_CTRL_time(seconds)'] >= bjj and row['std_avg_TD_att'] >= bjj:
        return 'BJJ'

    elif row['std_avg_CLINCH_att'] >= thai and row['std_avg_BODY_att'] >= thai and row['std_avg_LEG_att'] >= thai and row['std_avg_HEAD_att'] >= thai:
        return 'Thai'

    elif row['std_avg_DISTANCE_att'] >= sniper and row['std_avg_SIG_STR_pct'] >= sniper and row['std_avg_HEAD_att'] >= sniper and row['std_avg_BODY_att'] >= sniper and row['std_avg_LEG_att'] >= sniper:
        return 'Sniper'
    else:
        return 'Mixed'


dfdet = dfdet.copy()

# Apply the function to determine the style for each fighter
dfdet.loc[:, 'fighting_style'] = dfdet.apply(get_fighting_style, axis=1)

# Group by 'FIGHTING_STYLE' and get the count of each style in the group
style_counts = dfdet['fighting_style'].value_counts(normalize=True) * 100



merge_dfdet = dfdet[['fighter', 'fighting_style']]




################################################################################
################################################################################
################################################################################
# DFINST Cleaning



dfinst = dfinst.dropna(subset=['ROUND'])

dfinst.loc[:, 'ROUND'] = dfinst['ROUND'].str.replace('Round ', '').str.strip().astype(int)


# Sort the data by 'bout' and 'round' to make sure the last round is last
dfinst = dfinst.sort_values(by=['BOUT', 'FIGHTER', 'ROUND'], ascending=[True, True, False])

# Keep only the last round of each bout-fighter pair
dfinst = dfinst.drop_duplicates(subset=['BOUT', 'FIGHTER'], keep='first').reset_index(drop=True)


dfinst = dfinst[dfinst['ROUND'] != 1]
dfinst = dfinst[dfinst['SIG.STR. %'] != '---']
dfinst = dfinst[dfinst['TD %'] != '---']
dfinst = dfinst[dfinst['CTRL'] != '---']
dfinst = dfinst[dfinst['CTRL'] != '--']

dfinst['SIG.STR.'] = dfinst['SIG.STR.'].str.split(' of ').str[1].astype(int)
dfinst['SIG.STR. %'] = dfinst['SIG.STR. %'].str.replace('%', '').astype(int) / 100
dfinst['TOTAL STR.'] = dfinst['TOTAL STR.'].str.split(' of ').str[1].astype(int)
dfinst['TD'] = dfinst['TD'].str.split(' of ').str[1].astype(int)
dfinst['TD %'] = dfinst['TD %'].str.replace('%', '').astype(int) / 100
dfinst['CTRL'] = dfinst['CTRL'].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))
dfinst['HEAD'] = dfinst['HEAD'].str.split(' of ').str[1].astype(int)
dfinst['BODY'] = dfinst['BODY'].str.split(' of ').str[1].astype(int)
dfinst['LEG'] = dfinst['LEG'].str.split(' of ').str[1].astype(int)
dfinst['DISTANCE'] = dfinst['DISTANCE'].str.split(' of ').str[1].astype(int)
dfinst['CLINCH'] = dfinst['CLINCH'].str.split(' of ').str[1].astype(int)
dfinst['GROUND'] = dfinst['GROUND'].str.split(' of ').str[1].astype(int)


dfinst['OPPONENT'] = dfinst.apply(lambda row: row['BOUT'].split(' vs. ')[1] if row['BOUT'].split(' vs. ')[0] == row['FIGHTER'] else row['BOUT'].split(' vs. ')[0], axis=1)




dfinst = pd.merge(dfinst, merge_dfdet, left_on='FIGHTER', right_on='fighter', how='left')

# Rename the 'style' column to 'fighter_style'
dfinst = dfinst.rename(columns={'fighting_style': 'fighter_style'})
dfinst = dfinst.dropna(subset=['fighter_style'])
dfinst = dfinst.drop(columns=['fighter'])



dfinst = pd.merge(dfinst, merge_dfdet, left_on='OPPONENT', right_on='fighter', how='left')

# Rename the 'style' column to 'opponent_style'
dfinst = dfinst.rename(columns={'fighting_style': 'opponent_style'})

# Drop rows where the 'opponent_style' column is NaN
dfinst = dfinst.dropna(subset=['opponent_style'])

# Drop the extra 'fighter' column if no longer needed
dfinst = dfinst.drop(columns=['fighter'])
dfinst



exclude_columns = ['EVENT', 'BOUT', 'ROUND', 'FIGHTER', 'OPPONENT', 'fighter_style', 'opponent_style']

# Identify the columns that should be standardized (those not in the exclude_columns list)
columns_to_standardize = [col for col in dfinst.columns if col not in exclude_columns]

# Group by 'ROUND' and apply standardization to the selected columns
dfinst[['std_' + col for col in columns_to_standardize]] = dfinst.groupby('ROUND')[columns_to_standardize].transform(lambda x: (x - x.mean()) / x.std())




################################################################################


striker = 0.2
wrestler = -0.5
bjj = -0.75
thai = -0.5
sniper = -0.8

def get_fighting_style(row):
    if row['std_SIG.STR.'] >= striker and row['std_TOTAL STR.'] >= striker and row['std_HEAD'] >= striker:
        return 'Striker'

    elif row['std_CTRL'] >= wrestler and row['std_GROUND'] >= wrestler and row['std_TD'] >= wrestler:
        return 'Wrestler'

    elif row['std_SUB.ATT'] >= bjj and row['std_CTRL'] >= bjj and row['std_TD'] >= bjj:
        return 'BJJ'

    elif row['std_CLINCH'] >= thai and row['std_BODY'] >= thai and row['std_LEG'] >= thai and row['std_HEAD'] >= thai:
        return 'Thai'

    elif row['std_DISTANCE'] >= sniper and row['std_SIG.STR. %'] >= sniper and row['std_HEAD'] >= sniper and row['std_BODY'] >= sniper and row['std_LEG'] >= sniper:
        return 'Sniper'
    else:
        return 'Mixed'


dfinst = dfinst.copy()

# Apply the function to determine the style for each fighter
dfinst.loc[:, 'inst_style'] = dfinst.apply(get_fighting_style, axis=1)

# Group by 'FIGHTING_STYLE' and get the count of each style in the group
style_counts = dfinst['inst_style'].value_counts(normalize=True) * 100
style_counts




# Mapping for fighter styles and opponent styles
fighter_style_mapping = {
    'BJJ': 1,
    'Mixed': 2,
    'Sniper': 3,
    'Striker': 4,
    'Thai': 5,
    'Wrestler': 6
}

# Reverse mapping for decoding
reverse_fighter_style_mapping = {v: k for k, v in fighter_style_mapping.items()}

# Sample data setup (replace this with your actual `dfinst`)
# Assuming `dfinst` has columns: 'fighter_style', 'opponent_style', 'inst_style'
# Add encoded columns to the dataframe
dfinst['fighter_style_encoded'] = dfinst['fighter_style'].map(fighter_style_mapping)
dfinst['opponent_style_encoded'] = dfinst['opponent_style'].map(fighter_style_mapping)
dfinst['inst_style_encoded'] = dfinst['inst_style'].map(fighter_style_mapping)

# Initialize an empty dictionary to store proportions for each combination of styles
style_proportions = {}

# Loop through all combinations of fighter_style and opponent_style
for fighter_style in fighter_style_mapping.keys():
    for opponent_style in fighter_style_mapping.keys():

        # Filter data for the current combination of fighter and opponent styles
        style_data = dfinst[(dfinst['fighter_style'] == fighter_style) & (dfinst['opponent_style'] == opponent_style)]

        if style_data.shape[0] > 0:  # Ensure there's data for this combination
            # Group by the 'inst_style' and calculate the counts for each 'inst_style'
            inst_style_counts = style_data['inst_style'].value_counts(normalize=True)  # Proportions

            # Convert the proportions to percentages
            inst_style_percentages = inst_style_counts * 100  # Multiply by 100 to get percentages

            # Map the encoded values back to the original style names
            inst_style_percentages_mapped = inst_style_percentages.rename(reverse_fighter_style_mapping)

            # Store the proportions in the dictionary
            style_proportions[(fighter_style, opponent_style)] = inst_style_percentages_mapped.to_dict()



predicted_styles = []

# Loop through each row in the original DataFrame
for index, row in dfinst.iterrows():
    fighter_style = row['fighter_style']
    opponent_style = row['opponent_style']

    # Get the style proportions for this combination of styles
    if (fighter_style, opponent_style) in style_proportions:
        # Get the predicted inst_style (with highest probability)
        predicted_inst_style = max(style_proportions[(fighter_style, opponent_style)], key=style_proportions[(fighter_style, opponent_style)].get)
    else:
        predicted_inst_style = 'Unknown'  # In case no data is available for the combination

    # Append the prediction to the list
    predicted_styles.append(predicted_inst_style)

# Add the predicted inst_style column to the DataFrame
dfinst['predicted_inst_style'] = predicted_styles

style_counts = dfinst['predicted_inst_style'].value_counts(normalize=True) * 100
style_counts


import pickle


with open('style_proportions_model.pkl', 'wb') as f:
    pickle.dump(style_proportions, f)





df = pd.merge(df, merge_dfdet, left_on='RedFighter', right_on='fighter', how='left')

# Rename the 'style' column to 'fighter_style'
df = df.rename(columns={'fighting_style': 'fighter_style'})
df = df.dropna(subset=['fighter_style'])
df = df.drop(columns=['fighter'])



df = pd.merge(df, merge_dfdet, left_on='BlueFighter', right_on='fighter', how='left')

# Rename the 'style' column to 'opponent_style'
df = df.rename(columns={'fighting_style': 'opponent_style'})
# Drop rows where the 'opponent_style' column is NaN
df = df.dropna(subset=['opponent_style'])

# Drop the extra 'fighter' column if no longer needed
df = df.drop(columns=['fighter'])
df





# Function to get upcoming fights (same as before)
def get_first_event_fights():
    url = "http://ufcstats.com/statistics/events/upcoming"
    response = requests.get(url)
    if response.status_code != 200:
        print("Failed to retrieve data")
        return []

    soup = BeautifulSoup(response.text, "html.parser")

    # Get the first event link (only the first event on the page)
    first_event = soup.select_one('.b-link.b-link_style_black')
    if not first_event:
        print("No upcoming event found")
        return []

    first_event_url = first_event['href']

    # Scrape fights from this event
    event_response = requests.get(first_event_url)
    if event_response.status_code != 200:
        print("Failed to load event page")
        return []

    event_soup = BeautifulSoup(event_response.text, "html.parser")

    # Find all fighter names on the first event's fight card
    fighter_names = [f.text.strip() for f in event_soup.select(".b-fight-details__table-col .b-link")]

    # Filter out invalid names like "View Matchup"
    fighter_names = [name for name in fighter_names if "View Matchup" not in name and name]

    # Ensure only an even number of names are considered
    if len(fighter_names) % 2 != 0:
        print("Warning: Uneven number of fighters found. Some fights may be incomplete.")
        fighter_names = fighter_names[:-1]  # Remove the last name if it's unmatched

    # Pair fighters (each fight consists of two consecutive names)
    fights = [(fighter_names[i], fighter_names[i+1]) for i in range(0, len(fighter_names), 2)]

    return fights

fights = get_first_event_fights()



dfj

dfj['significant_striking_accuracy'] = dfj['significant_striking_accuracy'] / 100
dfj['significant_strike_defence'] = dfj['significant_strike_defence'] / 100
dfj['takedown_accuracy'] = dfj['takedown_accuracy'] / 100
dfj['takedown_defense'] = dfj['takedown_defense'] / 100



dfj = pd.merge(dfj, merge_dfdet, left_on='name', right_on='fighter', how='left')

# Rename the 'style' column to 'fighter_style'
dfj = dfj.rename(columns={'fighting_style': 'fighter_style'})
dfj['fighter_style_missing'] = dfj['fighter_style'].isna().astype(int)

dfj = dfj.drop(columns=['fighter'])

dfj = dfj.dropna(subset=['weight_in_kg'])

# Define weight classes
def get_weight_class(weight):
    if weight <= 57.6:
        return "Flyweight"
    elif weight <= 62.1:
        return "Bantamweight"
    elif weight <= 66.7:
        return "Featherweight"
    elif weight <= 71.2:
        return "Lightweight"
    elif weight <= 78:
        return "Welterweight"
    elif weight <= 84.8:
        return "Middleweight"
    elif weight <= 93.9:
        return "Light Heavyweight"
    elif weight <= 121.1:
        return "Heavyweight"
    else:
        return "Super Heavyweight"  # For fighters above 120.2 kg

# Apply function to create new column
dfj["weightclass"] = dfj["weight_in_kg"].apply(get_weight_class)
dfj['weightclass'].unique()


exclude_columns = ['name', 'nickname', 'wins', 'losses', 'draws', 'stance', 'date_of_birth', 'fighter_style', 'fighter_style_missing', 'weightclass']

# Identify the columns that should be standardized (those not in the exclude_columns list)
columns_to_standardize = [col for col in dfj.columns if col not in exclude_columns]

# Group by 'ROUND' and apply standardization to the selected columns
dfj[['std_' + col for col in columns_to_standardize]] = dfj.groupby('weightclass')[columns_to_standardize].transform(lambda x: (x - x.mean()) / x.std())




################################################################################


striker = 0
wrestler = -0.65
bjj = -0.95

def get_fighting_style(row):
    if row['std_significant_strikes_landed_per_minute'] >= striker and row['std_significant_striking_accuracy'] >= striker:
        return 'Striker'

    elif row['std_average_takedowns_landed_per_15_minutes'] >= wrestler and row['std_significant_strikes_landed_per_minute'] >= wrestler:
        return 'Wrestler'

    elif row['std_average_submissions_attempted_per_15_minutes'] >= bjj and row['std_average_takedowns_landed_per_15_minutes'] >= bjj:
        return 'BJJ'
    else:
        return 'Mixed'


dfj = dfj.copy()

# Apply the function to determine the style for each fighter
dfj.loc[dfj['fighter_style'].isna(), 'fighter_style'] = dfj.apply(get_fighting_style, axis=1)

# Group by 'FIGHTING_STYLE' and get the count of each style in the group
temp_filtered_df = dfj[dfj['fighter_style_missing'] == 1]

# Calculate the normalized style counts for the filtered rows
style_counts = temp_filtered_df['fighter_style'].value_counts(normalize=True) * 100

# Display the result
style_counts

dfj








chrome_options = Options()
chrome_options.add_argument("--headless")  # Run without a visible browser

driver = webdriver.Chrome(options=chrome_options)


def scrape_fight_odds():
    # Setup Chrome options
    chrome_options = Options()
    chrome_options.add_argument("--headless")  # Run in headless mode (no UI)
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")

    # Initialize the WebDriver
    driver = webdriver.Chrome(options=chrome_options)

    try:
        # Navigate to the website
        url = "https://fightodds.io/"
        driver.get(url)


        # Wait for the page to load
        time.sleep(3)

        # Find all rows in the table
        rows = driver.find_elements(By.XPATH, "//table/tbody/tr")


        # Initialize lists to store the data
        fighters = []
        odds = []

        # Iterate through each row
        for i, row in enumerate(rows):
            try:
                # Extract fighter name using a more robust relative XPath
                fighter_name_elem = row.find_element(By.XPATH, "./td[1]/a")
                fighter_name = fighter_name_elem.text.strip()

                # Extract odds using a more robust relative XPath
                odds_elem = row.find_element(By.XPATH, "./td[10]/button/span/div/div[1]/span")
                fighter_odds = odds_elem.text.strip()

                fighters.append(fighter_name)
                odds.append(fighter_odds)



            except Exception as e:
                print(f"Error extracting data from row {i+1}: {str(e)}")
                continue

        # Create a DataFrame to store the results
        fight_data = pd.DataFrame({
            'Fighter': fighters,
            'Odds': odds
        })

        # Save to CSV
        fight_data.to_csv('fighter_odds.csv', index=False)


        return fight_data

    except Exception as e:
        print(f"An error occurred: {str(e)}")

    finally:
        # Close the browser
        driver.quit()

if __name__ == "__main__":
    fight_data_odds = scrape_fight_odds()


fight_data_odds
dfj = pd.merge(dfj, fight_data_odds, how='left', left_on = 'name', right_on='Fighter')





def convert_odds_to_numeric(odds):
    if pd.isna(odds):  # Handle NaN values
        return np.nan
    elif odds.startswith('+'):
        return float(odds[1:])  # Convert positive odds to a number
    elif odds.startswith('-'):
        return float(odds)  # Convert negative odds to a number
    else:
        return np.nan  # Return NaN if the value doesn't match expected format

# Apply the conversion to the 'Odds_numerical' column
dfj['Odds_numerical'] = dfj['Odds'].apply(convert_odds_to_numeric)

# Function to calculate the expected value
def calculate_ev(odds):
    if pd.isna(odds):  # Check for NaN values
        return np.nan  # Return NaN if odds are not valid

    bet_amount = 100  # Bet amount is always 100

    if odds > 0:  # Positive odds (e.g., +200)
        p_win = 100 / (odds + 100)
        p_lose = 1 - p_win
        amount_won = bet_amount * (odds / 100)  # For +200 odds, you win $200 for every $100 bet
    else:  # Negative odds (e.g., -150)
        p_win = -odds / (-odds + 100)
        p_lose = 1 - p_win
        amount_won = bet_amount * (100 / -odds)  # For -150 odds, you win $100 for every $150 bet

    return amount_won

# Apply the profit calculation for each row in the DataFrame
dfj['expected_value'] = dfj['Odds_numerical'].apply(calculate_ev)
dfj['expected_value'] = np.log(dfj['expected_value'])




from datetime import datetime

# Convert 'date_of_birth' to datetime format
dfj['date_of_birth'] = pd.to_datetime(dfj['date_of_birth'], errors='coerce')

# Drop rows where 'date_of_birth' is NaT
dfj = dfj.dropna(subset=['date_of_birth'])

# Calculate age by subtracting the birth year from the current year
today = datetime.today()
dfj['age'] = today.year - dfj['date_of_birth'].dt.year

# Adjust age for those who haven't had their birthday yet this year
dfj['age'] = dfj['age'] - ((dfj['date_of_birth'].dt.month > today.month) |
                           ((dfj['date_of_birth'].dt.month == today.month) & (dfj['date_of_birth'].dt.day > today.day)))







matchup_dfs = {}

# List of variables to compute the difference for (you can add more variables to this list)
variables_to_compare = ['wins', 'losses', 'height_cm', 'reach_in_cm', 'significant_strikes_landed_per_minute', 'significant_striking_accuracy',
                        'significant_strikes_absorbed_per_minute', 'significant_strike_defence', 'average_takedowns_landed_per_15_minutes',
                        'takedown_accuracy', 'takedown_defense', 'average_submissions_attempted_per_15_minutes', 'expected_value', 'age']  # Example






for i, (fighter1, fighter2) in enumerate(fights, start=1):
    # Filter the DataFrame for the two fighters and make an explicit copy
    df_pair = dfj[dfj['name'].isin([fighter1, fighter2])].copy()

    # Add the opponent fighting style column
    df_pair.loc[df_pair['name'] == fighter1, 'opponent_style'] = df_pair.loc[df_pair['name'] == fighter2, 'fighter_style'].values[0]
    df_pair.loc[df_pair['name'] == fighter2, 'opponent_style'] = df_pair.loc[df_pair['name'] == fighter1, 'fighter_style'].values[0]

    # For each variable, calculate the difference and add it as a new column
    for var in variables_to_compare:
        # Make sure the variable exists in the DataFrame and calculate differences
        if var in df_pair.columns:
            # Calculate the difference for fighter1 - fighter2 and fighter2 - fighter1
            fighter1_value = df_pair.loc[df_pair['name'] == fighter1, var].values[0]
            fighter2_value = df_pair.loc[df_pair['name'] == fighter2, var].values[0]

            # Compute the correct difference for both fighters
            df_pair.loc[df_pair['name'] == fighter1, f'{var}_diff'] = fighter1_value - fighter2_value
            df_pair.loc[df_pair['name'] == fighter2, f'{var}_diff'] = fighter2_value - fighter1_value

    # Assign the updated DataFrame to the dictionary with the appropriate key
    matchup_dfs[f"df{i}"] = df_pair




# Function to load the saved style proportions model
def load_model():
    with open('style_proportions_model.pkl', 'rb') as f:
        style_proportions_model = pickle.load(f)
    return style_proportions_model

# Function to apply the model to a new dataframe
def apply_model_to_df(df, style_proportions_model):
    """
    Apply the trained model (proportions) to make predictions on a new dataframe.

    Args:
    - df: DataFrame with columns ['fighter_style', 'opponent_style']
    - style_proportions_model: The trained model containing style proportions

    Returns:
    - df: DataFrame with an additional 'predicted_inst_style' column
    """
    predicted_styles = []

    # Loop through each row in the new dataframe
    for index, row in df.iterrows():
        fighter_style = row['fighter_style']
        opponent_style = row['opponent_style']

        # Get the style proportions for this combination of styles
        if (fighter_style, opponent_style) in style_proportions_model:
            # Get the predicted inst_style (with highest probability)
            predicted_inst_style = max(style_proportions_model[(fighter_style, opponent_style)],
                                       key=style_proportions_model[(fighter_style, opponent_style)].get)
        else:
            predicted_inst_style = 'Unknown'  # In case no data is available for the combination

        # Append the prediction to the list
        predicted_styles.append(predicted_inst_style)

    # Add the predicted inst_style column to the new dataframe
    df['predicted_inst_style'] = predicted_styles

    return df

# Load the model
style_proportions_model = load_model()

# Apply the model to each dataframe in the matchup_dfs dictionary
for key, matchup_df in matchup_dfs.items():
    matchup_dfs[key] = apply_model_to_df(matchup_df, style_proportions_model)

# Example: Check the first updated matchup DataFrame
matchup_dfs['df5']




for key, dat in matchup_dfs.items():
    dftemp = dat.copy()  # Make a copy of the DataFrame to avoid changing the original one

    dftemp.rename(columns={
        'expected_value_diff': 'DiffExpectedValue',
        'significant_strikes_landed_per_minute_diff': 'DiffAvgSigStrLanded',
        'significant_striking_accuracy_diff': 'DiffAvgSigStrPct',
        'average_submissions_attempted_per_15_minutes_diff': 'DiffAvgSubAtt',
        'average_takedowns_landed_per_15_minutes_diff': 'DiffAvgTDLanded',
        'takedown_accuracy_diff': 'DiffAvgTDPct',
        'losses_diff': 'DiffLosses',
        'wins_diff': 'DiffWins',
        'height_cm_diff': 'DiffHeightCms',
        'reach_in_cm_diff': 'DiffReachCms',
        'age_diff': 'DiffAge',
    }, inplace=True)

    matchup_dfs[key] = dftemp




df = df.dropna(subset=['opponent_style'])
df = df.dropna(subset=['fighter_style'])
df = df[~df['WeightClass'].isin(['Catch Weight', "Women's Featherweight", "Women's Strawweight", "Women's Flyweight", "Women's Bantamweight"])]
columns_to_drop = ['DiffExpectedValue', 'DiffAvgSigStrLanded', 'DiffAvgSigStrPct', 'DiffAvgSubAtt', 'DiffAvgTDLanded', 'DiffAvgTDPct', 'DiffLosses', 'DiffWins', 'DiffHeightCms', 'DiffReachCms', 'DiffAge']
df = df.dropna(subset=columns_to_drop)


# Dictionary to store models
models = {}


# Function to load the appropriate model based on the WeightClass and fighter_style
def load_model(weight_class, fighter_style):
    model_filename = f'model_{weight_class}_{fighter_style}.pkl'
    try:
        model = joblib.load(model_filename)
        return model
    except FileNotFoundError:
        print(f"Model for {weight_class} - {fighter_style} not found.")
        return None

# When saving models, we should also save the feature names
# Add this to your training code
for (weight_class, fighter_style), group in df.groupby(['WeightClass', 'fighter_style']):
    # One-hot encode the categorical variable: 'opponent_style'
    group_encoded = pd.get_dummies(group, columns=['opponent_style'], drop_first=True)

    # Select the independent variables (features) and dependent variable (target)
    feature_cols = ['DiffExpectedValue', 'DiffAvgSigStrLanded', 'DiffAvgSigStrPct',
                   'DiffAvgSubAtt', 'DiffAvgTDLanded', 'DiffAvgTDPct', 'DiffLosses',
                   'DiffWins', 'DiffHeightCms', 'DiffReachCms', 'DiffAge'] + \
                  [col for col in group_encoded if col.startswith('opponent_style_')]

    X = group_encoded[feature_cols]
    y = group_encoded['WinnerBinary']

    # Ensure there are enough samples to train a model
    if len(group) < 5:  # Adjust threshold based on data size
        continue

    # Train-test split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=69)

    # Train model
    model = LinearRegression()
    model.fit(X_train, y_train)

    # Save the model and feature names
    model_data = {
        'model': model,
        'feature_names': feature_cols
    }
    model_filename = f'model_{weight_class}_{fighter_style}.pkl'
    joblib.dump(model_data, model_filename)

    # Store the model in the dictionary with the (weight_class, fighter_style) as the key
    models[(weight_class, fighter_style)] = model_data

# Function to apply the model and make predictions
def apply_model_to_matchup(row, models):
    weight_class = row['weightclass']
    fighter_style = row['predicted_inst_style']

    # Check if any covariates have NaN values
    covariates = ['DiffExpectedValue', 'DiffAvgSigStrLanded', 'DiffAvgSigStrPct', 'DiffAvgSubAtt',
                  'DiffAvgTDLanded', 'DiffAvgTDPct', 'DiffLosses', 'DiffWins', 'DiffHeightCms',
                  'DiffReachCms', 'DiffAge']

    if row[covariates].isna().any():  # If any covariate is NaN
        return np.nan  # Return NaN for the prediction

    # Load the model for this matchup
    model_data = models.get((weight_class, fighter_style))

    if model_data is None:
        # If the model doesn't exist, return NaN for the prediction
        return np.nan

    model = model_data['model']
    feature_names = model_data['feature_names']

    # Create a feature vector with all expected features
    features = {}

    # Add the numeric features
    for col in covariates:
        features[col] = row[col]

    # Add zeros for all possible opponent_style features
    for feat in feature_names:
        if feat.startswith('opponent_style_'):
            features[feat] = 0

    # Set the appropriate opponent_style feature to 1
    # Note: We need to handle the case where this opponent_style wasn't in the training data
    opponent_style_col = f'opponent_style_{row["opponent_style"]}'
    if opponent_style_col in features:
        features[opponent_style_col] = 1

    # Convert to DataFrame to ensure feature order matches model expectations
    features_df = pd.DataFrame([features])
    # Ensure columns are in the same order as during training
    features_df = features_df[feature_names]

    # Make the prediction using the model
    prediction = model.predict(features_df)[0]
    return prediction

# Apply the model to each row in the matchup DataFrame and scale predictions to sum to 1
for key, dat in matchup_dfs.items():
    # Apply the model function to each dataframe in the dictionary
    dat['predicted_winner'] = dat.apply(lambda row: apply_model_to_matchup(row, models), axis=1)

    # Now scale the predictions so they sum to 1 for each matchup
    # Get the sum of predictions for this matchup
    total_prediction = dat['predicted_winner'].sum()

    # If total prediction is 0 or NaN, set equal probabilities
    if total_prediction == 0 or pd.isna(total_prediction):
        dat['predicted_winner_scaled'] = 0.5  # Equal chance for both fighters
    else:
        # Scale each prediction by dividing by the sum
        dat['predicted_winner_scaled'] = dat['predicted_winner'] / total_prediction

    # Calculate implied probability from odds
    dat['implied_probability'] = dat.apply(lambda row:
        # For negative odds (favorites, e.g., -150)
        abs(row['Odds_numerical']) / (abs(row['Odds_numerical']) + 100) if row['Odds_numerical'] < 0
        # For positive odds (underdogs, e.g., +150)
        else 100 / (row['Odds_numerical'] + 100), axis=1)

    # Scale implied probabilities to sum to 1 (removing the bookmaker's margin)
    total_implied_prob = dat['implied_probability'].sum()
    dat['implied_probability_scaled'] = dat['implied_probability'] / total_implied_prob

    # Update the dictionary with the modified DataFrame
    matchup_dfs[key] = dat





# Define thresholds for bet sizing
threshold_1_unit = 0.1 # 5% edge
threshold_2_unit = 0.30  # 10% edge
threshold_3_unit = 0.5  # 15% edge

# Loop through each matchup to determine bet sizes
for key, dat in matchup_dfs.items():
    # Calculate the edge (difference between your prediction and market-implied probability)
    dat['betting_edge'] = dat['predicted_winner_scaled'] - dat['implied_probability_scaled']

    # Determine bet size based on edge
    def determine_bet_size(row):
        edge = row['betting_edge']

        # No bet if edge is negative (model thinks fighter is less likely to win than odds suggest)
        if edge <= 0:
            return 0

        # Apply bet sizing based on thresholds
        if edge >= threshold_3_unit:
            return 3
        elif edge >= threshold_2_unit:
            return 2
        elif edge >= threshold_1_unit:
            return 1
        else:
            return 0

    dat['bet_size'] = dat.apply(determine_bet_size, axis=1)

    # Update the dictionary with the modified DataFrame
    matchup_dfs[key] = dat



# Function to scrape UFC fight title
def scrape_ufc_fight_title():
    url = "http://www.ufcstats.com/statistics/events/completed"

    try:
        response = requests.get(url)

        if response.status_code == 200:
            tree = html.fromstring(response.content)
            fight_title = tree.xpath('/html/body/section/div/div/div/div[2]/div/table/tbody/tr[2]/td[1]/i/a/text()')

            if fight_title and len(fight_title) > 0:
                return fight_title[0].strip()
            else:
                return "Unknown_Fight"
        else:
            print(f"Failed to fetch the webpage. Status code: {response.status_code}")
            return "Unknown_Fight"

    except Exception as e:
        print(f"An error occurred: {str(e)}")
        return "Unknown_Fight"

# Get the fight title
fight_title = scrape_ufc_fight_title()

# Clean the fight title to make it suitable for a filename
# Remove special characters and replace spaces with underscores
clean_title = re.sub(r'[^\w\s]', '', fight_title).replace(' ', '_')



# Create a directory for exports if it doesn't exist
os.makedirs('exports', exist_ok=True)

# Combine all matchup dataframes into one for exporting
all_matchups = pd.DataFrame()

for key, dat in matchup_dfs.items():
    # Add a column to identify which matchup this is
    dat['matchup_id'] = key

    # Add only rows where bet_size > 0 (if you only want to export bets)
    # Comment this line out if you want to export all matchups
    dat = dat[dat['bet_size'] > 0]

    # Append to the combined dataframe
    all_matchups = pd.concat([all_matchups, dat])

# Select only the columns you want to export
export_columns = [
    'matchup_id', 'name', 'Odds', 'bet_size',
    'predicted_winner_scaled', 'implied_probability_scaled', 'betting_edge'
]
all_matchups = all_matchups.round(3)
+

# If 'name' is not in your columns, adjust as needed
export_columns = [col for col in export_columns if col in all_matchups.columns]

# Export to CSV
export_path = 'exports/betting_recommendations.csv'
all_matchups[export_columns].to_csv(export_path, index=False)




# GitHub API parameters
github_token = "xqc"  # You should regenerate this token for security
repo_owner = "zwinship"
repo_name = "UFC_Model"

# Create file name with date and fight title
file_name = f"betting_recommendations_{clean_title}.csv"
path = f"predictions/{file_name}"

# Read the CSV file
with open('exports/betting_recommendations.csv', 'r') as file:
    content = file.read()

# Encode content to base64
content_encoded = base64.b64encode(content.encode()).decode()

# GitHub API endpoint for creating or updating a file
url = f"https://api.github.com/repos/{repo_owner}/{repo_name}/contents/{path}"

# Headers for authentication
headers = {
    "Authorization": f"token {github_token}",
    "Accept": "application/vnd.github.v3+json"
}

# Data for the API request
data = {
    "message": f"Update betting recommendations for {fight_title} {datetime.now().strftime('%Y-%m-%d')}",
    "content": content_encoded
}

# First check if the file exists
check_url = f"https://api.github.com/repos/{repo_owner}/{repo_name}/contents/{path}"
check_response = requests.get(check_url, headers=headers)

if check_response.status_code == 200:
    # File exists, get the SHA
    file_sha = check_response.json()['sha']
    data['sha'] = file_sha  # Add SHA to your data for update
    print(f"Updating existing file: {file_name}")
else:
    print(f"Creating new file: {file_name}")

# Send the request
response = requests.put(url, headers=headers, json=data)

if response.status_code == 201:
    print(f"File created: {file_name}")
elif response.status_code == 200:
    print(f"File updated: {file_name}")
else:
    print(f"Error: {response.status_code}")
    print(response.json())





import sys
sys.exit(0)