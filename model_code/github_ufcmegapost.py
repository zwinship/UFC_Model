# -*- coding: utf-8 -*-
"""github_UFCmegapost.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LQFFnjTw3fKVe8l1ke-ji_PMm3htUSS2
"""

import pandas as pd
import requests
import base64
import json
import re
import io
import sys
from datetime import datetime
from bs4 import BeautifulSoup
from lxml import html

# Function to scrape UFC fight title
def pre_scrape_ufc_fight_title():
    url = "http://www.ufcstats.com/statistics/events/completed"

    try:
        response = requests.get(url)

        if response.status_code == 200:
            tree = html.fromstring(response.content)
            fight_title = tree.xpath('/html/body/section/div/div/div/div[2]/div/table/tbody/tr[3]/td[1]/i/a/text()')

            if fight_title and len(fight_title) > 0:
                return fight_title[0].strip()
            else:
                return "Unknown_Fight"
        else:
            print(f"Failed to fetch the webpage. Status code: {response.status_code}")
            return "Unknown_Fight"

    except Exception as e:
        print(f"An error occurred: {str(e)}")
        return "Unknown_Fight"

# Function to get first fighters from the first completed event
def get_first_completed_event_fighters():
    url = "http://ufcstats.com/statistics/events/completed"
    response = requests.get(url)
    if response.status_code != 200:
        print("Failed to retrieve data")
        return [], ""

    soup = BeautifulSoup(response.text, "html.parser")

    # Get all event links
    event_links = soup.select('.b-link.b-link_style_black')
    if not event_links:
        print("No completed events found")
        return [], ""

    # Get the first event link (index 0)
    first_event = event_links[0]
    first_event_url = first_event['href']
    event_name = first_event.text.strip()
    print(f"Fetching data for: {event_name}")

    # Scrape fights from this event
    event_response = requests.get(first_event_url)
    if event_response.status_code != 200:
        print("Failed to load event page")
        return [], ""

    event_soup = BeautifulSoup(event_response.text, "html.parser")

    # Find all fighter names on the first event's fight card
    fighter_names = [f.text.strip() for f in event_soup.select(".b-fight-details__table-col .b-link")]

    # Filter out invalid names like "View Matchup"
    fighter_names = [name for name in fighter_names if "View Matchup" not in name and name]

    # Ensure only an even number of names are considered
    if len(fighter_names) % 2 != 0:
        print("Warning: Uneven number of fighters found. Some fights may be incomplete.")
        fighter_names = fighter_names[:-1]  # Remove the last name if it's unmatched

    # Keep only the first fighter from each pair
    first_fighters = [fighter_names[i] for i in range(0, len(fighter_names), 2)]

    return first_fighters, event_name

# Function to calculate potential winnings from American odds
def calculate_winnings(row, odds_col, bet_size_col):
    # Only calculate winnings if the fighter is in the first event
    if row['won'] == 1:
        odds = row[odds_col]
        bet_size = row[bet_size_col]

        # For positive odds (underdog): (odds/100) * bet_size
        if odds > 0:
            return round((odds/100) * bet_size, 3)
        # For negative odds (favorite): (100/abs(odds)) * bet_size
        else:
            return round((100/abs(odds)) * bet_size, 3)
    else:
        return 0  # Return 0 if the fighter is not in the first event

# Get the fight title
pre_fight_title = pre_scrape_ufc_fight_title()

# Clean the fight title to make it suitable for a filename
pre_clean_title = re.sub(r'[^\w\s]', '', pre_fight_title).replace(' ', '_')

# Load data
dfpre = pd.read_csv(f"https://raw.githubusercontent.com/zwinship/UFC_Model/refs/heads/main/predictions/betting_recommendations_{pre_clean_title}.csv")


# Get the first fighters from the first completed event
first_fighters, event_name = get_first_completed_event_fighters()

# Process the data if fighters are found
if first_fighters:
    print(f"Found {len(first_fighters)} first fighters from {event_name}:")
    for i, fighter in enumerate(first_fighters, 1):
        print(f"Fighter {i}: {fighter}")

    # Display available columns in dfpre
    print("\nAvailable columns in your DataFrame:")
    print(dfpre.columns.tolist())

    # Find the closest column names for odds and bet size
    odds_col = None
    bet_size_col = None

    for col in dfpre.columns:
        if col.lower() == 'odds':
            odds_col = col
        elif col.lower() == 'bet_size':
            bet_size_col = col

    # If columns aren't found, ask the user
    if odds_col is None:
        print("\nCouldn't find 'Odds' column. Please specify which column contains the odds:")
        odds_col = input("Enter odds column name: ")

    if bet_size_col is None:
        print("\nCouldn't find 'bet_size' column. Please specify which column contains the bet sizes:")
        bet_size_col = input("Enter bet size column name: ")

    # Create a new column in dfpre with value 1 if the fighter is in first_fighters
    dfpre['won'] = dfpre['name'].apply(lambda x: 1 if x in first_fighters else 0)

    # Calculate potential winnings based on American odds and bet size
    dfpre['potential_winnings'] = dfpre.apply(lambda row: calculate_winnings(row, odds_col, bet_size_col), axis=1)

    # Add a column for total return (bet_size + profit) for winners
    dfpre['total_return'] = round(dfpre.apply(
        lambda row: row[bet_size_col] + row['potential_winnings'] if row['won'] == 1 else 0,
        axis=1
    ), 3)

    dfpre['profit'] = round(dfpre['total_return'] - dfpre['bet_size'], 3)

    # Add event name and date columns to track when this data was collected
    today = datetime.now().strftime('%Y-%m-%d')
    dfpre['event_name'] = event_name
    dfpre['date_added'] = today

    print("\nUpdated DataFrame with betting calculations:")
    print(dfpre)

    # Calculate total potential profit
    total_investment = dfpre[bet_size_col].sum()
    total_potential_return = dfpre['total_return'].sum()
    potential_winnings = total_potential_return - total_investment

    # GitHub API parameters (using provided credentials)
    github_token = "erobb221"
    repo_owner = "zwinship"
    repo_name = "UFC_Model"

    # Create a clean version of the event name for the filename
    clean_title = event_name.strip().replace(' ', '_').replace(':', '').replace(',', '')

    # Create file name with date and fight title
    file_name = f"betting_results_{clean_title}_{today}.csv"
    path = f"results/{file_name}"

    # First save to local CSV
    local_path = "betting_results.csv"
    dfpre.to_csv(local_path, index=False)
    print(f"Saved results to local file: {local_path}")

    # Read the CSV file
    with open(local_path, 'r') as file:
        content = file.read()

    # Encode content to base64
    content_encoded = base64.b64encode(content.encode()).decode()

    # GitHub API endpoint for creating or updating a file
    url = f"https://api.github.com/repos/{repo_owner}/{repo_name}/contents/{path}"

    # Headers for authentication
    headers = {
        "Authorization": f"token {github_token}",
        "Accept": "application/vnd.github.v3+json"
    }

    # Data for the API request
    data = {
        "message": f"Update betting results for {event_name} {today}",
        "content": content_encoded
    }

    # First check if the file exists
    check_url = f"https://api.github.com/repos/{repo_owner}/{repo_name}/contents/{path}"
    check_response = requests.get(check_url, headers=headers)

    if check_response.status_code == 200:
        # File exists, get the SHA
        file_sha = check_response.json()['sha']
        data['sha'] = file_sha  # Add SHA to your data for update
        print(f"Updating existing file: {file_name}")
    else:
        print(f"Creating new file: {file_name}")

    # Send the request
    response = requests.put(url, headers=headers, json=data)

    if response.status_code == 201:
        print(f"File created: {file_name}")
    elif response.status_code == 200:
        print(f"File updated: {file_name}")
    else:
        print(f"Error: {response.status_code}")
        print(response.json())

    # Now let's also append to a master CSV that tracks all bets
    file_name = "all_betting_results.csv"
    master_path = f"results/{file_name}"
    # Check if master file exists
    master_url = f"https://api.github.com/repos/{repo_owner}/{repo_name}/contents/{master_path}"
    master_response = requests.get(master_url, headers=headers)

    if master_response.status_code == 200:
        # Master file exists, get content
        master_content = base64.b64decode(master_response.json()['content']).decode('utf-8')
        master_sha = master_response.json()['sha']

        # Read existing CSV into DataFrame
        existing_df = pd.read_csv(io.StringIO(master_content))
        print(f"Existing master CSV has {len(existing_df)} rows")

        # Append new data
        combined_df = pd.concat([existing_df, dfpre], ignore_index=True)
        print(f"Combined master CSV will have {len(combined_df)} rows")

        # Convert back to CSV string
        master_csv_content = combined_df.to_csv(index=False)
        master_encoded = base64.b64encode(master_csv_content.encode()).decode()

        # Update master file
        master_data = {
            "message": f"Append betting results for {event_name} {today}",
            "content": master_encoded,
            "sha": master_sha
        }

        master_update = requests.put(master_url, headers=headers, json=master_data)

        if master_update.status_code == 200:
            print(f"Master file updated with new results")
        else:
            print(f"Error updating master file: {master_update.status_code}")
            print(master_update.json())
    else:
        # Master file doesn't exist, create it
        master_csv_content = dfpre.to_csv(index=False)
        master_encoded = base64.b64encode(master_csv_content.encode()).decode()

        master_data = {
            "message": f"Create master betting results file with {event_name} {today}",
            "content": master_encoded
        }

        master_create = requests.put(master_url, headers=headers, json=master_data)

        if master_create.status_code == 201:
            print(f"Master file created with initial results")
        else:
            print(f"Error creating master file: {master_create.status_code}")
            print(master_create.json())
else:
    print("No fighters found")

sys.exit(0)